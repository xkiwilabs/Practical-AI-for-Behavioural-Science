# Week 1: Additional Readings and Resources

> **Note:** The required reading for this week is the [companion reading](README.md) (the `README.md` in this folder). The readings below are **optional** — they provide additional depth and are a great place to find papers for your presentation and written assignment.

## Suggested Readings

These are short, accessible papers that provide excellent background for the topics covered in Week 1. We recommend reading at least one before (or after) the lecture.

### 1. Yarkoni, T., & Westfall, J. (2017). Choosing prediction over explanation in psychology: Lessons from machine learning. *Perspectives on Psychological Science, 12*(6), 1100–1122. https://doi.org/10.1177/1745691617693393

*Why read this:* This is the foundational paper arguing that psychology should embrace prediction alongside its traditional focus on explanation. Highly readable, and directly relevant to the central theme of this course. **Open access** — free PDF available via [PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC6603289/).

### 2. Obermeyer, Z., & Emanuel, E. J. (2016). Predicting the future — Big data, machine learning, and clinical medicine. *The New England Journal of Medicine, 375*(13), 1216–1219. https://doi.org/10.1056/NEJMp1606181

*Why read this:* A very short paper (4 pages) that gives a non-technical overview of how machine learning is changing healthcare research. A good warm-up if you've never encountered ML before. **Free** via [PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC5070532/).

---

## Optional / Deeper Readings

These go deeper into specific topics from the lecture. Read them if something from the lecture sparked your curiosity.

### 3. Hagendorff, T., Fabi, S., & Kosinski, M. (2023). Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT. *Nature Computational Science, 3*, 833–838. https://doi.org/10.1038/s43588-023-00527-x

*Why read this:* A fascinating study that tested LLMs on classic cognitive psychology tasks — the kind you've studied in cognitive science courses. Shows how larger language models develop human-like biases, and how ChatGPT can engage in more deliberate reasoning. Published in *Nature Computational Science*.

### 4. Binz, M., Schulz, E., et al. (2025). A foundation model to predict and capture human cognition. *Nature, 644*(8078), 1002–1009. https://doi.org/10.1038/s41586-025-09215-4

*Why read this:* The team created Psych-101, a massive dataset of 60,000+ participants making 10 million+ choices across 160 experiments, and used it to fine-tune an LLM (Centaur) that predicts human behaviour better than traditional cognitive models. A landmark demonstration of ML as a tool for building unified theories of cognition. **Open access** — free preprint on [arXiv](https://arxiv.org/abs/2410.20268).

### 5. Dwyer, D. B., Falkai, P., & Koutsouleris, N. (2018). Machine learning approaches for clinical psychology and psychiatry. *Annual Review of Clinical Psychology, 14*, 91–118. https://doi.org/10.1146/annurev-clinpsy-032816-045037

*Why read this:* A comprehensive review of how ML is being used in clinical psychology and psychiatry — from diagnosis to treatment prediction. Good for understanding the clinical applications of the methods we'll cover.

### 6. Hassabis, D., Kumaran, D., Summerfield, C., & Botvinick, M. (2017). Neuroscience-inspired artificial intelligence. *Neuron, 95*(2), 245–258. https://doi.org/10.1016/j.neuron.2017.06.011

*Why read this:* For cognitive science students especially — this paper explores the two-way relationship between neuroscience and AI. Written by researchers at DeepMind (including CEO Demis Hassabis), it argues that understanding the brain can inspire better AI, and vice versa. **Open access.**

### 7. Auletta, F., Kallen, R. W., di Bernardo, M., & Richardson, M. J. (2023). Predicting and understanding human action decisions during skillful joint-action using supervised machine learning and explainable-AI. *Scientific Reports, 13*, 4992. https://doi.org/10.1038/s41598-023-31807-1

*Why read this:* A direct demonstration of ML + explainable AI applied to understanding human behaviour in a collaborative task. Shows how ML models can reveal things about human decision-making that traditional methods miss. **Open access.**

### 8. Argyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Rytting, C., & Wingate, D. (2023). Out of one, many: Using language models to simulate human samples. *Political Analysis, 31*(3), 337–351. https://doi.org/10.1017/pan.2023.2

*Why read this:* Demonstrates how LLMs can be conditioned with demographic backstories to simulate human survey responses — creating "silicon samples" that reproduce real survey distributions. Raises important questions about using AI in social science research. Preprint available on [arXiv](https://arxiv.org/abs/2209.06899).

### 9. Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? In *Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency* (pp. 610–623). ACM. https://doi.org/10.1145/3442188.3445922

*Why read this:* The paper that coined the term "stochastic parrots" for LLMs — arguing that these models stitch together sequences of words based on statistical patterns without any reference to meaning. An important counterpoint to claims about LLM intelligence, and directly relevant to the discussion questions in the companion reading. [Free PDF](https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf).

### 10. Onnela, J.-P., & Rauch, S. L. (2016). Harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. *Neuropsychopharmacology, 41*(7), 1691–1696. https://doi.org/10.1038/npp.2016.7

*Why read this:* An early and influential paper on digital phenotyping — using passive smartphone sensor data to understand and predict mental health. Raises key questions about privacy, ethics, and the potential of ML in clinical settings. **Open access** via [PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC4869063/).

### 11. Kelso, J. A. S. (1995). *Dynamic patterns: The self-organization of brain and behavior.* MIT Press.

*Why read this:* The foundational text on how brains and behaviour exhibit features of complex dynamical systems — multistability, phase transitions, and self-organisation. Directly relevant to the Week 1 discussion about whether ML models can predict human behaviour because behaviour is more structured and deterministic than it appears.

### 12. Thelen, E., & Smith, L. B. (1994). *A dynamic systems approach to the development of cognition and action.* MIT Press. https://doi.org/10.7551/mitpress/2524.001.0001

*Why read this:* A landmark book showing that development — reaching, walking, learning — follows complex dynamical principles rather than pre-programmed stages. Changed how developmental and cognitive scientists think about where behaviour comes from.

### 13. Van Orden, G. C., Holden, J. G., & Turvey, M. T. (2003). Self-organization of cognitive performance. *Journal of Experimental Psychology: General, 132*(3), 331–350. https://doi.org/10.1037/0096-3445.132.3.331

*Why read this:* Found fractal patterns in cognitive performance — reaction times, reading, categorisation — suggesting that cognition itself is a self-organising process rather than a sequence of discrete stages. A key paper in the complex systems approach to psychology.

### 14. Warren, W. H. (2006). The dynamics of perception and action. *Psychological Review, 113*(2), 358–389. https://doi.org/10.1037/0033-295X.113.2.358

*Why read this:* Shows that perception and action are coupled dynamical systems, with behaviour emerging from the continuous interaction between body, brain, and environment. A clear, well-written argument for why psychology needs dynamical systems thinking.

### 15. Richardson, M. J., Dale, R., & Marsh, K. L. (2014). Complex dynamical systems in social and personality psychology: Theory, modeling, and analysis. In H. T. Reis & C. M. Judd (Eds.), *Handbook of research methods in social and personality psychology* (2nd ed., pp. 253–282). Cambridge University Press. https://doi.org/10.1017/CBO9780511996481.015

*Why read this:* Extends complex systems thinking to social coordination and interpersonal dynamics — how people synchronise movements, coordinate conversations, and create emergent group behaviour. Shows how dynamical systems methods apply across the full range of psychological phenomena, from neurons to social interaction.

---

## Recommended Books

**There is no single required textbook for this course.** Weekly readings and companion materials are your primary resources. However, if you want deeper understanding of the methods we cover, here are our recommendations:

### Start Here

**James, G., Witten, D., Hastie, T., Tibshirani, R., & Taylor, J. (2023).** *An introduction to statistical learning: With applications in Python.* Springer. **Free PDF:** [statlearning.com](https://www.statlearning.com/)

This is the best single reference for understanding the ML methods we cover in Weeks 3–10. The Python edition (ISLP) was published in 2023 — use this over the older R edition. It's clear, applied, and not overly mathematical. The free PDF is legitimately available from the authors' website.

### For Hands-On Learners

**Géron, A. (2022).** *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow* (3rd ed.). O'Reilly.

Very practical and hands-on — great if you learn by doing. Strong coverage of neural networks and ML pipelines. Note: the code examples in this book are useful reference, but in this course you'll be using LLM assistants to help write code rather than typing everything from scratch.

### For the LLM/AI Weeks (9–11)

**Alammar, J., & Grootendorst, M. (2024).** *Hands-on large language models: Language understanding and generation.* O'Reilly.

Covers transformer architecture, embeddings, semantic search, and retrieval-augmented generation. Jay Alammar is known for excellent visual explanations of how transformers work. Maarten Grootendorst holds masters degrees in both psychology and data science — a perfect crossover for our course. Best for when we hit embeddings, text analysis, and LLM concepts.

### For the Psychology Angle

**Jacobucci, R., Grimm, K. J., & Zhang, Z. (2023).** *Machine learning for social and behavioral research.* Guilford Press.

Written specifically for social and behavioural scientists. Addresses ML in the context of psychological research questions, and covers how ML relates to the traditional statistics you may have encountered in earlier courses. A good bridge between "stats you know" and "ML methods you're learning."

### Additional References

**Tunstall, L., von Werra, L., & Wolf, T. (2022).** *Natural language processing with Transformers* (revised ed.). O'Reilly.

More "NLP practitioner" focused — useful when we cover embeddings, text analysis, and transformer concepts. Keep as an optional extension; it's more technical than most students will need.

**Ghosh, C. (2022).** *Data analysis with machine learning for psychologists.* Springer.

Explicitly aimed at psychologists. "Crash course" in tone — useful as a quick reference but not as in-depth as the ISLP textbook or Jacobucci for sustained learning.

> **You don't need to buy any of these.** The ISLP textbook is free, and you can access O'Reilly books through the [Macquarie University Library's online collection](https://www.mq.edu.au/library).

### Which Book Chapters Match Which Weeks?

If you want to read ahead or dive deeper, here's how the recommended books align with our weekly topics:

| Week | Topic | ISLP Chapter | Géron Chapter | Other |
|------|-------|-------------|---------------|-------|
| 1 | Intro to ML/AI | Ch 1–2 | Ch 1 | Jacobucci Ch 1 |
| 3 | Generalisation & Overfitting | Ch 2, 5 | Ch 2 | — |
| 4 | Regression Pipeline | Ch 3, 6 | Ch 4 | — |
| 5 | Classification & Evaluation | Ch 4 | Ch 3 | — |
| 6 | Trees & Ensembles | Ch 8 | Ch 6–7 | — |
| 7 | Clustering & Dim. Reduction | Ch 12 | Ch 8–9 | — |
| 9 | Neural Networks | Ch 10 | Ch 10–11 | — |
| 11 | Embeddings & LLMs | — | Ch 16 | Alammar Ch 1–5 |

---

## Tool and Resource Links

- **Semantic Scholar** — [semanticscholar.org](https://semanticscholar.org) — AI-powered academic search engine
- **NotebookLM** — [notebooklm.google.com](https://notebooklm.google.com) — Upload papers, get AI summaries
- **Elicit** — [elicit.com](https://elicit.com) — Evidence synthesis from 200M+ papers
- **Consensus** — [consensus.app](https://consensus.app) — Research questions answered from peer-reviewed literature

---

*[Back to Week 1](README.md) · [Back to course overview](../../README.md)*
